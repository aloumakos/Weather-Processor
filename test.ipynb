{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gefs.20231111/06/atmos/pgrb2ap5/gec00.t06z.pgrb2a.0p50.f000\n",
      "An error occurred (404) when calling the HeadObject operation: Not Found\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "from datetime import datetime, date\n",
    "import time\n",
    "import pygrib\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "ct_df = pd.read_csv(\"usregions.csv\")[:30000]\n",
    "lls = list(zip(ct_df['lat'], ct_df['lng']))\n",
    "last_report = pd.read_csv(\"report.csv\").to_dict()\n",
    "report_dict = {\n",
    "        \"Date\": [(date.today()+relativedelta(days=i)).strftime(\"%a, %d %b %Y\") for i in range(15)],\n",
    "        \"Current FC\": [],\n",
    "        \"FC 6 hours ago\": last_report['Current FC'],\n",
    "        \"FC 12 hours ago\": last_report['FC 6 hours ago'],\n",
    "        \"FC 18 hours ago\": last_report['FC 12 hours ago'],\n",
    "        \"FC 24 hours ago\": last_report['FC 18 hours ago'],\n",
    "        \"Diff 12 hours ago\": [],\n",
    "        \"Diff 24 hours ago\": []\n",
    "    }\n",
    "dt = datetime.now()\n",
    "file_dt = \"\".join(list(map(str,[dt.year,dt.month,f\"{dt.day:02d}\"])))\n",
    "\n",
    "client = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "bucket = client.list_objects(Bucket='noaa-gefs-pds', Prefix = \"gefs.\"+file_dt+\"/\", Delimiter=\"/\",)\n",
    "\n",
    "while True:\n",
    "    if bucket.get('CommonPrefixes') is not None:\n",
    "        fldr = bucket.get('CommonPrefixes')[-1].get('Prefix')\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(300)\n",
    "\n",
    "cycle = fldr.split('/')[-2]\n",
    "base = f'{fldr[:-1]}/atmos/pgrb2ap5/gec00.t{cycle}z.pgrb2a.0p50.f'\n",
    "files = []\n",
    "for i in range(0,243,3):\n",
    "    files.append(base+f\"{i:03d}\")\n",
    "for i in range(246,390,6):\n",
    "    files.append(base+f\"{i}\")\n",
    "\n",
    "\n",
    "def process(file, cycle):\n",
    "    grbs = pygrib.open(file)\n",
    "    grb = grbs.select(name='Temperature')[-1]\n",
    "    data = grb.data()[0]\n",
    "    \n",
    "    def f(lat, lon):\n",
    "        return round(abs(data[int(round(-2*lat)+180),int(round(2*lon))]*1.8-459.67-65),2)\n",
    "    \n",
    "    ct_df['dd_'+cycle] = [f(lat, lon) for lat,lon in lls]\n",
    "    \n",
    "    grbs.close()\n",
    "def _to_state(x):\n",
    "    return pd.Series({'dd':(x['population'] * x['dd']/x['population'].sum()).sum(),'population': x['population'].sum()})\n",
    "def _to_region(x):\n",
    "    return pd.Series({'dd':(x['population'] * x['dd']/x['population'].sum()).sum(),'population': x['population'].sum()})\n",
    "while files:\n",
    "    idx = int(files[0].split(\".\")[-1][-3:])\n",
    "\n",
    "    print(files[0])\n",
    "    try:\n",
    "        if idx%24==0 and idx>0:\n",
    "            ct_df['dd'] = (ct_df['dd_00']+ct_df['dd_03']+ct_df['dd_06']+ct_df['dd_09']+ct_df['dd_12']+ct_df['dd_15']+ct_df['dd_18']+ct_df['dd_21'])/8\n",
    "            state_df = ct_df.groupby(['state_name','region'])[['population', 'dd']].apply(_to_state).reset_index()\n",
    "            region_df = state_df.groupby(['region'])[['population','dd']].apply(_to_region).reset_index()\n",
    "            national_dd = round((region_df['population']*region_df['dd']).sum()/region_df['population'].sum(),2)\n",
    "            report_dict['Current FC'].append(national_dd)\n",
    "            \n",
    "            report_df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in report_dict.items() ]))\n",
    "            report_df['Diff 12 hours ago'] = report_df['Current FC']-report_df['FC 12 hours ago']\n",
    "            report_df['Diff 24 hours ago'] = report_df['Current FC']-report_df['FC 24 hours ago']\n",
    "            report_df.to_csv('report.csv')\n",
    "        client.download_file('noaa-gefs-pds', files[0], 'temp')\n",
    "        process('temp', f\"{idx%24:02d}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        # time.sleep(60)\n",
    "        break\n",
    "    del files[0]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Current FC</th>\n",
       "      <th>FC 6 hours ago</th>\n",
       "      <th>FC 12 hours ago</th>\n",
       "      <th>FC 18 hours ago</th>\n",
       "      <th>FC 24 hours ago</th>\n",
       "      <th>Diff 12 hours ago</th>\n",
       "      <th>Diff 24 hours ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat, 11 Nov 2023</td>\n",
       "      <td>14.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun, 12 Nov 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon, 13 Nov 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, 14 Nov 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, 15 Nov 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thu, 16 Nov 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fri, 17 Nov 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sat, 18 Nov 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sun, 19 Nov 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mon, 20 Nov 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tue, 21 Nov 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wed, 22 Nov 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Thu, 23 Nov 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fri, 24 Nov 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sat, 25 Nov 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date  Current FC  FC 6 hours ago  FC 12 hours ago  \\\n",
       "0   Sat, 11 Nov 2023       14.64             NaN              NaN   \n",
       "1   Sun, 12 Nov 2023         NaN             NaN              NaN   \n",
       "2   Mon, 13 Nov 2023         NaN             NaN              NaN   \n",
       "3   Tue, 14 Nov 2023         NaN             NaN              NaN   \n",
       "4   Wed, 15 Nov 2023         NaN             NaN              NaN   \n",
       "5   Thu, 16 Nov 2023         NaN             NaN              NaN   \n",
       "6   Fri, 17 Nov 2023         NaN             NaN              NaN   \n",
       "7   Sat, 18 Nov 2023         NaN             NaN              NaN   \n",
       "8   Sun, 19 Nov 2023         NaN             NaN              NaN   \n",
       "9   Mon, 20 Nov 2023         NaN             NaN              NaN   \n",
       "10  Tue, 21 Nov 2023         NaN             NaN              NaN   \n",
       "11  Wed, 22 Nov 2023         NaN             NaN              NaN   \n",
       "12  Thu, 23 Nov 2023         NaN             NaN              NaN   \n",
       "13  Fri, 24 Nov 2023         NaN             NaN              NaN   \n",
       "14  Sat, 25 Nov 2023         NaN             NaN              NaN   \n",
       "\n",
       "    FC 18 hours ago  FC 24 hours ago  Diff 12 hours ago  Diff 24 hours ago  \n",
       "0               NaN              NaN                NaN                NaN  \n",
       "1               NaN              NaN                NaN                NaN  \n",
       "2               NaN              NaN                NaN                NaN  \n",
       "3               NaN              NaN                NaN                NaN  \n",
       "4               NaN              NaN                NaN                NaN  \n",
       "5               NaN              NaN                NaN                NaN  \n",
       "6               NaN              NaN                NaN                NaN  \n",
       "7               NaN              NaN                NaN                NaN  \n",
       "8               NaN              NaN                NaN                NaN  \n",
       "9               NaN              NaN                NaN                NaN  \n",
       "10              NaN              NaN                NaN                NaN  \n",
       "11              NaN              NaN                NaN                NaN  \n",
       "12              NaN              NaN                NaN                NaN  \n",
       "13              NaN              NaN                NaN                NaN  \n",
       "14              NaN              NaN                NaN                NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_df = pd.read_csv(\"uscities.csv\")\n",
    "states_to_regions = {\"Washington\": \"Pacific\", \"Oregon\":\"Pacific\",\"California\":\"Pacific\",\"Nevada\":\"Mountain\",\"Wyoming\":\"Mountain\",\"Arizona\":\"Mountain\",\"Montana\":\"Mountain\",\"Idaho\":\"Mountain\",\"Utah\":\"Mountain\",\"Colorado\":\"Mountain\",\"New Mexico\":\"Mountain\",\"North Dakota\":\"Midwest\",\"South Dakota\":\"Midwest\",\"Nebraska\":\"Midwest\",\"Kansas\":\"Midwest\",\"Minnesota\":\"Midwest\",\"Iowa\":\"Midwest\",\"Missouri\":\"Midwest\",\"Wisconsin\":\"Midwest\",\"Michigan\":\"Midwest\",\"Illinois\":\"Midwest\",\"Indiana\":\"Midwest\",\"Ohio\":\"Midwest\",\"New York\":\"Northeast\",\"Pennsylvania\":\"Northeast\",\"New Jersey\":\"Northeast\",\"Vermont\":\"Northeast\",\"New Hampshire\":\"Northeast\",\"Maine\":\"Northeast\",\"Massachusetts\":\"Northeast\",\"Rhode Island\":\"Northeast\",\"Connecticut\":\"Northeast\",\"Texas\":\"South\",\"Oklahoma\":\"South\",\"Arkansas\":\"South\",\"Louisiana\":\"South\",\"North Carolina\":\"South\",\"South Carolina\":\"South\",\"Florida\":\"South\",\"Georgia\":\"South\",\"West Virginia\":\"South\",\"Virginia\":\"South\",\"Delaware\":\"South\",\"Maryland\":\"South\",\"Tennessee\":\"South\",\"Mississippi\":\"South\",\"Alabama\":\"South\",\"Kentucky\":\"South\",\"District of Columbia\":\"South\",\"Puerto Rico\":\"lol\",\"Hawaii\":\"lol\",\"Alaska\":\"lol\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_df[\"region\"] =[states_to_regions[x] for x in ct_df[\"state_name\"]]\n",
    "\n",
    "ct_df.drop(ct_df[ct_df[\"region\"]==\"lol\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_df.to_csv(\"usregions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
